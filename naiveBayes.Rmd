---
title: "Machine Learning Workflow-Naive Bayes"
author: "Bella Feng"
date: "November 16, 2017"
output: html_document
mainfont: Arial
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```
###Machine Learning with R: Naive Bayes
Strengths:
• Simple, fast, and very effective  
• Does well with noisy and missing data  
• Requires relatively few examples for training, but also works well with very large numbers of examples  
• Easy to obtain the estimated probability for a prediction  
Weaknesses:  
• Relies on an often-faulty assumption of equally important and independent features-->Naive  
• Not ideal for datasets with large numbers of numeric features  
• Estimated probabilities are less reliable than the predicted classes  

The workflow consists of 7 steps

#####<span style="color:blue">1. Load data</span>
#####<span style="color:blue">2. Observe data</span>
#####<span style="color:blue">3. Preprocess data</span>
#####<span style="color:blue">4. Split the data</span>
#####<span style="color:blue">5. Train a model</span>
#####<span style="color:blue">6. Evaluate the model</span>
#####<span style="color:blue">7. Improve model performance</span>
 

###<span style="color:blue">1. Load data</span>
```{r echo=FALSE}
sms_raw <- read.csv("C:/Users/gfeng/Documents/_datascience/Machine-Learning-with-R-datasets-master/sms_spam.csv", stringsAsFactors=FALSE)
#install.packages("class")
#install.packages("gmodels")
# libraries needed by caret
library(klaR)
library(MASS)
# for the Naive Bayes modelling
library(caret)
# to process the text into a corpus
library(tm)
# to get nice looking tables
library(pander)
# to simplify selections
library(dplyr)
```
###<span style="color:blue">2. Observe data</span>
```{r}
str(sms_raw)
dim(sms_raw)
```


our y variable: type, need to be a factor
```{r}
table(sms_raw$type)
str(sms_raw$type)
table(sms_raw$type)
```

###<span style="color:blue">3. Preprocess data</span>
Text processing steps:
1. create a corpus & inspect
The Corpus() function stores the result in an object named sms_corpus.Since we have already read the SMS messages and stored them in an R vector, we specify VectorSource(), which tells Corpus() to use the messages in the vector sms_train$text.

```{r}
library(tm)
sms_corpus <- Corpus(VectorSource(sms_raw$text))
#str(sms_corpus)
print(sms_corpus)
inspect(sms_corpus[1:3])
```
2. Clean up the corpus: to lower cases, remove numbers, punctuation, stop words, remove extra white spaces
```{r}
corpus_clean <- tm_map(sms_corpus, tolower)
corpus_clean <- tm_map(corpus_clean, removeNumbers)
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())
corpus_clean <- tm_map(corpus_clean, removePunctuation)
sms_corpus_clean <- tm_map(corpus_clean, stripWhitespace)
#inspect(corpus_clean[1:3])
```
3. Tokenization: The DocumentTermMatrix() function will take a corpus and create a data structure called a sparse matrix, in which the rows of the matrix indicate documents (that is, SMS messages) and the columns indicate terms (that is, words).
```{r}
sms_dtm <- DocumentTermMatrix(corpus_clean)
```


###<span style="color:blue">4. Split the data</span>
We'll begin by splitting the raw data frame:
```{r}
sms_raw_train <- sms_raw[1:4179, ]
sms_raw_test <- sms_raw[4180:5574, ]
```

Then the document-term matrix:
```{r}
sms_dtm_train <- sms_dtm[1:4179, ]
sms_dtm_test <- sms_dtm[4180:5573, ]
```


And finally, the corpus:
```{r}
sms_corpus_train <- corpus_clean[1:4179]
sms_corpus_test <- corpus_clean[4180:5573]
```

To confirm that the subsets are representative of the complete set of SMS data, let's
compare the proportion of spam in the training and test data frames:
```{r}
prop.table(table(sms_raw_train$type))
prop.table(table(sms_raw_test$type))
```
```{r}
library(wordcloud)
wordcloud(sms_corpus_train, min.freq = 40, random.order = FALSE)
```

```{r}
library(wordcloud)
 spam <- subset(sms_raw_train, type == "spam")
 ham <- subset(sms_raw_train, type == "ham")
 wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
```
The final step in the data preparation process is to transform the sparse matrix into a
data structure that can be used to train a naive Bayes classifier.
```{r}
frequent_terms <- findFreqTerms(sms_dtm_train,5)
sms_dtm_freq_train <- sms_dtm_train[,frequent_terms]
sms_dtm_freq_test <- sms_dtm_test[,frequent_terms]

```



The naive Bayes classifier is typically trained on data with categorical features. This
poses a problem since the cells in the sparse matrix indicate a count of the times a
word appears in a message. We should change this to a factor variable that simply
indicates yes or no depending on whether the word appears at all.
The following code defines a convert_counts() function to convert counts to factors:
```{r}
convert_counts <- function(x){
  x <- ifelse(x > 0,"Yes","No")
}
sms_train <- apply(sms_dtm_freq_train,MARGIN = 2,   convert_counts)
sms_test <- apply(sms_dtm_freq_test,MARGIN = 2,     convert_counts)
```



###<span style="color:blue">5. Train a model</span>
```{r echo=FALSE}

library(e1071)

# a utility function for % freq tables
frqtab <- function(x, caption) {
  round(100*prop.table(table(x)), 1)
}
# utility function to summarize model comparison results
sumpred <- function(cm) {
  summ <- list(TN=cm$table[1,1],  # true negatives
               TP=cm$table[2,2],  # true positives
               FN=cm$table[1,2],  # false negatives
               FP=cm$table[2,1],  # false positives
               acc=cm$overall["Accuracy"],  # accuracy
               sens=cm$byClass["Sensitivity"],  # sensitivity
               spec=cm$byClass["Specificity"])  # specificity
  lapply(summ, FUN=round, 2)
}
# if (!file.exists("smsspamcollection.zip")) {
#   download.file(url="http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/smsspamcollection.zip",
#                 destfile="smsspamcollection.zip", method="curl")
# }
# sms_raw <- read.table(unz("smsspamcollection.zip","SMSSpamCollection"),
#                       header=FALSE, sep="\t", quote="", stringsAsFactors=FALSE)
sms_raw <- read.csv("C:/Users/gfeng/Documents/_datascience/Machine-Learning-with-R-datasets-master/sms_spam.csv", stringsAsFactors=FALSE)
#sms_raw <- sms_raw[1:10, ]
colnames(sms_raw) <- c("type", "text")
sms_raw$type <- factor(sms_raw$type)
# randomize it a bit
set.seed(12358)
sms_raw <- sms_raw[sample(nrow(sms_raw)),]
str(sms_raw)

sms_corpus <- Corpus(VectorSource(sms_raw$text))
sms_corpus_clean <- sms_corpus %>%
  tm_map(content_transformer(tolower)) %>% 
  tm_map(removeNumbers) %>%
  tm_map(removeWords, stopwords(kind="en")) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
sms_dtm <- DocumentTermMatrix(sms_corpus_clean)

train_index <- createDataPartition(sms_raw$type, p=0.75, list=FALSE)
sms_raw_train <- sms_raw[train_index,]
sms_raw_test <- sms_raw[-train_index,]
sms_corpus_clean_train <- sms_corpus_clean[train_index]
sms_corpus_clean_test <- sms_corpus_clean[-train_index]
sms_dtm_train <- sms_dtm[train_index,]
sms_dtm_test <- sms_dtm[-train_index,]

ft_orig <- frqtab(sms_raw$type)
ft_train <- frqtab(sms_raw_train$type)
ft_test <- frqtab(sms_raw_test$type)
ft_df <- as.data.frame(cbind(ft_orig, ft_train, ft_test))
colnames(ft_df) <- c("Original", "Training set", "Test set")
pander(ft_df, style="rmarkdown",
       caption=paste0("Comparison of SMS type frequencies among datasets"))
sms_dict <- findFreqTerms(sms_dtm_train, lowfreq=5)
sms_train <- DocumentTermMatrix(sms_corpus_clean_train, list(dictionary=sms_dict))
sms_test <- DocumentTermMatrix(sms_corpus_clean_test, list(dictionary=sms_dict))

# modified sligtly fron the code in the book
convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0)
  x <- factor(x, levels = c(0, 1), labels = c("Absent", "Present"))
}
sms_train <- sms_train %>% apply(MARGIN=2, FUN=convert_counts)
sms_test <- sms_test %>% apply(MARGIN=2, FUN=convert_counts)

ctrl <- trainControl(method="cv", 10)
set.seed(12358)
```
```{r}
sms_model1 <- train(sms_train, sms_raw_train$type, method="nb",
                    trControl=ctrl)
sms_test_pred <- predict(sms_model1, sms_test)
library(gmodels)
CrossTable(sms_test_pred, sms_raw_test$type,
           prop.chisq = FALSE, prop.t = FALSE,
           dnn = c('predicted', 'actual'))
```



